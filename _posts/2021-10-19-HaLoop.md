---
title: 'HaLoop: Efficient Iterative Data Processing
on Large Clusters'
categories: [Paper Review]
comments: true
---

# Abstract
기존 맵리듀스는 반복적인~iterative~ 작업에 대한 지원이 부족했다. iterative 한 작업은 데이터 마이닝, 웹 랭킹 등 많은 작업을 포함한다. `HaLoop` 은 하둡의 수정 버전으로, 이러한 작업들을 수행하기 위해 설계되었다. 

# Introduction

하둡으로 비싸고 어렵고 fault-tolerance 하지 않은 병렬 컴퓨팅을 그렇지 않고 할 수 있게 해주는 잘 알려진 프레임워크이다. 하지만, 많은 데이터 분석 기술은 *iterative* 한 계산이 필요하다. 이것이 필요한 기술들에는 공통적인 특징이 있다. 데이터가 수렴하거나 멈추는 조건에 도달할 때 까지 반복적으로 계산을 수행한다는 것이다. 맵리듀스는 이를 직접 제공하진 않는다. 대신, 사용자가 직접 여러 맵리듀스 작업을 만들고 드라이버를 통해 이들을 조율하여 반복 프로그램을 구현해야 한다.<br>
이 때는 두 가지 문제가 있다.
* 반복되어도 데이터가 변하지 않는다.
    * 리프로세싱과 리로딩 과정이 필요하다.
    * 대역폭과 I/O 가 낭비된다.
* 종료 조건을 감지해야 하지만, 연속되는 반복에서 출력이 변하지 않는다.
    * 추가적인 맵리듀스 작업이 필요하다.

이 논문에서는 `HaLoop` 이라는, 이런 작업들을 효율적으로 다루기 위해 고안된 시스템을 설명한다. 이는 맵리듀스를 기반으로 하고 두 간단한 직관에 기반한다. 
* 맵리듀스 클러스터는 첫 반복에서 불변하는 데이터를 입시 저장하고, 다음 반복에 재사용한다.
* 맵리듀스 클러스터는 리듀서의 출력을 임시 저장하고, 이는 추가 맵리듀스 작업 없이 fixpoint를 확인하기 쉽게 한다.

# Overvies

## Architecture
시스템이 하나의 마스터 노드와 다수의 슬레이브 노드로 두 파트로 나뉜다. 마스터 노드는 슬레이브 노드를 실행시키기 위한 병렬 작업의 수를 조정한다. 각 슬레이브 노드는 작업의 실행을 관리하고 마스터 노드와 소통하기 위한 task tracker 프로세스를 가지고 있다. 이는 caching, indexing 작업을 수행한다.<br>
이 시스템이 기본 하둡과 다른 점이 몇 개 있다.
1. 반복 맵리듀스 프로그램의 표현을 단순화시켜서 나타내기 위해 새로운 인터페이스를 보여준다.
2. 하룹의 마스터 노드는 , 사용자가 정의한 조건에 도달할 때 까지 새로운 맵 리듀스 단계를 반복적으로 시작하는 새로운 반복 컨트롤 모듈을 포함한다.
3. 하룹은 데이터 로컬리티를 유지하기 위한 반복 작업을 위한 새로운 태스크 스케줄러를 사용한다.
4. 하룹은 슬레이브 노드에 데이터를 캐싱하고 인덱싱한다.

# Loop-Aware Task Scheduling
하룹 스케줄러의 목표는 다른 iteration 에서 수행되지만 같은 데이터에 엑세스하는 맵과 리듀스 작업을 같은 물리적 장치에 위치시키는 것이다. 이를 통해 iteration 간 반복과 재사용이 쉬워진다.

# Ca