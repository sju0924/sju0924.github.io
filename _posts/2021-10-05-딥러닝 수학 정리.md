---
title: '딥러닝 수학 정리'
categories: [study]
comments: true
---

# 기계 학습에서의 수학
* 수학은 목적함수를 정의하고, 목적함수가 최저가 되는 점을 찾아주는 최적화 이론 제공
* 최적화 이론에 규제,모멘텀 등 제어를 추가해 알고리즘 구축

# 선형대수
## 벡터
* 샘플을 특징 벡터로 표현한다.
## 행렬
* 여러 개의 벡터를 담는다.
* 훈련집합을 담은 행렬을 설계행렬이라 부른다.

### 전치행렬
Aij를 Aji로 옮기는 것.

### 행렬 연산
* 곱셈
    * 교환법칙 성립 x
    * 분배법칙과 결합법칙 성립
* 벡터의 내적
    * i번째 요소를 곱한 값을 더한다.

### 텐서
3차원 이상의 구조를 가진 숫자 배열
### Norm

> 벡터의 크기를 구하는 방법

노름, 혹은 놈이라고 불린다. 차수에 따라 1,2,3,..,n차 놈으로 표현할 수 있다
n차 놈은, 벡터의 각 요소들을 n제곱 한 것에 절대값을 씌운 값을 더하고, n제곱근을 씌운다. 

#### 최대 놈
n이 무한에 근접하게 되면 최대 놈이 된다. 따라서 최대 놈은 벡터에서 가장 큰 요소의 절댓값으로 나타낼 수 있다.

#### 프로베니우스 놈
2차 놈을 프로베니우스 놈이라고도 한다.

#### in python

``` python
np.linalg.norm(arr,ord = n)
```
으로 n차 놈을 나타낼 수 있다.

``` python
np.linalg.norm(arr,'fro')
```
로 프로베니우스 놈을 나타낸다.

# 확률 이론


